# -*- coding: utf-8 -*-
"""AAPL_Machine_Learning_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gboPQU4UbAeIPmEpdNHJo9Em9nddKPO_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR

# %matplotlib inline

np.random.seed(42)

data = pd.read_csv("AAPL.csv").drop(['Close'], axis=1)
data.set_index('Date', drop=True, inplace=True)

"""This is a machine learning algo, used to predict the adjusted closing price of AAPL (Apple Inc.) 10 *trading days* in the future."""

data.head()

data['Adj Close'].plot()

X = data['Adj Close'].shift(10).dropna()
y = data['Adj Close']

trainX, testX, trainY, testY = train_test_split(X.values, y[10:].values, test_size=.2)

trainX, trainY, testX, testY = trainX.reshape(-1, 1), trainY.reshape(-1, 1), testX.reshape(-1, 1), testY.reshape(-1, 1)

"""Now that we have looked at the data, and split it into training and testing datasets, we can create our model."""

lr = Pipeline([
    ("scaler", StandardScaler()),
    ("lr", LinearRegression())
])

"""To create our model, we are just going to use a standard scaler, and Linear Regression.  Now we can use cross-validation to test our model."""

kfold = KFold(n_splits=10)
lr_score = cross_val_score(lr, trainX, trainY, cv=kfold, scoring='neg_mean_squared_error')

lr_score.mean()

"""This means that on average, the model will be $2.06 off of the actual price."""

lr.fit(trainX, trainY)

preds = lr.predict(testX)

plt.plot([a for a in range(len(testY))], testY, 'r-', label='actual')
plt.plot([a for a in range(len(preds))], preds, 'g--', label='model')
plt.legend()
plt.show()

lr.predict([[157.74]])

"""Now that we are sure that our model is working fine, we can backtest our model.  Since we trained our model on data from 2013 to 2018, we are going to backtest using data from 2009 to 2013."""

backtest = pd.read_csv("AAPL_Backtest.csv")

errors = []
money = 1000.0
counter = 0
pred = None
last_price = None

for price in backtest['Adj Close'].values[::10]:
  if counter == 0:
    pred = lr.predict([[price]])
  else:
    errors.append(pred - price)
    pred = lr.predict([[price]])
  
  
  counter += 1

"""Not lets find the average dollar amount that our model was off by."""

sum(errors) / len(errors)

errors

"""Conclusion:  While this was a fun example, in real life it won't do too much, for a few reasons.

1).  In real life, stock prices are far more complex than linear regression can handle.
2).  Past closing prices aren't really a great indicator of when to buy a stock.


We can also improve this by testing it on more than just $AAPL.  We can also include more data from recessions.  Since our data is only from 2013-2018, not many large recessions like in 2008 are included.  Therefore, our model will have no experience of what to do when in a recession.
"""