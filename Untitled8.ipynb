{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quant-Projects/Algo-Trading-Examples/blob/master/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LQDYYiEnNaea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_1o24BKNmpi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0h7utVSMQSqP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exploratory Phase"
      ]
    },
    {
      "metadata": {
        "id": "HSz86VY3NpmS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not that we have imported our training data, lets start with the exploratory phase.  We are first going to view the data, statistics of the data, and find and replace any missing values."
      ]
    },
    {
      "metadata": {
        "id": "-q3ltgnaN2iV",
        "colab_type": "code",
        "outputId": "cb468392-1d62-42bf-9f7f-29ca1d514b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "SiZ6vZ0iN5HA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Just looking at our data, there are a few columns that we don't need.  For starters, we will want to get rid of the IDs.  We will also want to get rid of the cabin, as well the ticket number.  And just for this tutorial, we are also going to get rid of the names of the passengers too (if you want a challenge, you can use feature engineering to create new features from the deleted columns)."
      ]
    },
    {
      "metadata": {
        "id": "jRsaZLMxOikx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SE7zG_xOOpCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have only the data that we need, we should look at the data types of the remaining columns.\n",
        "\n",
        "If the dtype of a column is an object or a string, then we will want to convert that the something machine learning readable.  For this example, we are going to convert them to dummy variables using \n",
        "\n",
        "```\n",
        "pd.get_dummies(df)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wDhl0dG1PBnm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train['Sex'] = pd.get_dummies(train['Sex'])\n",
        "train['Embarked'] = pd.get_dummies(train['Embarked'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mnRWNZD1PIQY",
        "colab_type": "code",
        "outputId": "907d658c-5563-441b-94ca-72429de4bd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
              "0         0       3    0  22.0      1      0   7.2500         0\n",
              "1         1       1    1  38.0      1      0  71.2833         1\n",
              "2         1       3    1  26.0      0      0   7.9250         0\n",
              "3         1       1    1  35.0      1      0  53.1000         0\n",
              "4         0       3    0  35.0      0      0   8.0500         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "-vsWkdR7PLig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, now that everything appears to be ML readable, then get some of the stats using ```df.describe()``` and ```df.info()```.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "scwayIdOPeV3",
        "colab_type": "code",
        "outputId": "42a998e6-7dd8-4ea1-c0a8-c210e738297b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>0.352413</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "      <td>0.188552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>0.477990</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "      <td>0.391372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
              "count  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000   \n",
              "mean     0.383838    2.308642    0.352413   29.699118    0.523008    0.381594   \n",
              "std      0.486592    0.836071    0.477990   14.526497    1.102743    0.806057   \n",
              "min      0.000000    1.000000    0.000000    0.420000    0.000000    0.000000   \n",
              "25%      0.000000    2.000000    0.000000   20.125000    0.000000    0.000000   \n",
              "50%      0.000000    3.000000    0.000000   28.000000    0.000000    0.000000   \n",
              "75%      1.000000    3.000000    1.000000   38.000000    1.000000    0.000000   \n",
              "max      1.000000    3.000000    1.000000   80.000000    8.000000    6.000000   \n",
              "\n",
              "             Fare    Embarked  \n",
              "count  891.000000  891.000000  \n",
              "mean    32.204208    0.188552  \n",
              "std     49.693429    0.391372  \n",
              "min      0.000000    0.000000  \n",
              "25%      7.910400    0.000000  \n",
              "50%     14.454200    0.000000  \n",
              "75%     31.000000    0.000000  \n",
              "max    512.329200    1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "aUUUR4qHPiee",
        "colab_type": "code",
        "outputId": "a3f2259b-90ee-4148-b81a-3e9143a619a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 8 columns):\n",
            "Survived    891 non-null int64\n",
            "Pclass      891 non-null int64\n",
            "Sex         891 non-null uint8\n",
            "Age         714 non-null float64\n",
            "SibSp       891 non-null int64\n",
            "Parch       891 non-null int64\n",
            "Fare        891 non-null float64\n",
            "Embarked    891 non-null uint8\n",
            "dtypes: float64(2), int64(4), uint8(2)\n",
            "memory usage: 43.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JgxCzLWvPnen",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking at the stats, we can learn a few useful things about the data.  For one, since the mean survived variable is 0.38, most of the passengers did not live.  Another thing is that since the mean age was a little over 29 years, we can say that the people on board were somewhat young.  Lastly, since the mean sex was about 0.35, we can also say that the people were majority male. \n",
        "\n",
        "You can get so much more from just these simple reports, but we are going to move on.  If you want, we can try to come up with some more assumptions from the stats youself."
      ]
    },
    {
      "metadata": {
        "id": "dcbroQSzQP0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have learned something about the variable, we need to look to see what is missing.  To do this, we are going to use ```df.isnull().any()```."
      ]
    },
    {
      "metadata": {
        "id": "k7Zfzau6Qk4I",
        "colab_type": "code",
        "outputId": "5bf4c604-4271-48b9-b54f-05200b6bd4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "train.isnull().any()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived    False\n",
              "Pclass      False\n",
              "Sex         False\n",
              "Age          True\n",
              "SibSp       False\n",
              "Parch       False\n",
              "Fare        False\n",
              "Embarked    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "wM7FLzwxQmnP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking at the output, we can say that the only column with any missing values is the age column.  \n",
        "\n",
        "Now before we just start randomly filling and/or removing missing values, we need to do some detective work.  For this part, we are going to use our brain, and attempt to assume the reason that the data is missing.\n",
        "\n",
        "For the most part there is only two reasons that data could go missing, someone didn't record it, or it doesn't exist.  Since the part where data goes missing because it isn't recorded correctly, we are just going to give an example about data that doesn't exist. \n",
        "\n",
        "Imagine that I am interviewing people randomly and asking them their favorite ice cream flavor.  If I ask some people that we alergic to ice cream, then they would of course not have a favorite flavor.  Therefore, there will be missing data for them.  Now, the interviewer could decide to leave those people out, but in many cases, they decide to leave it in provived that not too much of the data is left empty.\n",
        "\n",
        "Now in the case where data doesn't exist, it may be best to just replace data with the most common value, the mean, mode, etc. (provided that not too much of the data is missing).  However, if the data just wasn't recorded, we can just remove it.\n",
        "\n",
        "Now in our example, I find that it is very rare that someone's age doesn't exist.  So, in this example it isn't a good idea to just remove it.  We are instead going to replace it with the mean.  (Plus is you looked, there are too much missing data to simple remove them)."
      ]
    },
    {
      "metadata": {
        "id": "pkm31wayS5ry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train['Age'].fillna(value=train['Age'].mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvNq84hUTZ-i",
        "colab_type": "code",
        "outputId": "b7478fd1-f1b9-44d6-f127-7d52c0746052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#now let's check it see if it worked!\n",
        "train.isnull().any()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived    False\n",
              "Pclass      False\n",
              "Sex         False\n",
              "Age         False\n",
              "SibSp       False\n",
              "Parch       False\n",
              "Fare        False\n",
              "Embarked    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "9AUdXOL87SJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e190beea-750f-4b98-aa34-2752a8633658"
      },
      "cell_type": "code",
      "source": [
        "train.drop(['Survived'], axis=1).shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "QSnPADofTf_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now if you want to go above and beyond, you can examine the distributions of the data, correlations, and so on.  But for this guide, we are just going to start in with the model design phase."
      ]
    },
    {
      "metadata": {
        "id": "0HNQHaVpTz5w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Design Phase"
      ]
    },
    {
      "metadata": {
        "id": "AwUnHxMLT2fG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now looking back at our previous guides, we used simply supervised learning models.  However, the highest we ever got on the test set was aout 80% accuracy (this was even with Random Forest).  So, for this guide, we are going to attemp to beat this score using an ANN (artificial neural network) designed by Tensorflow."
      ]
    },
    {
      "metadata": {
        "id": "YvYTtfw-UQ0G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For our model, we are going to use a simple network with 2 hidden layers using RELU (since RELU usually converges faster).  Now before we just start coding, we are just going to lay our the detals of our ANN architecture. \n",
        "\n",
        "To start, we need to know how many nodes to have in our input layer.  This is very easy, since the number of nodes in our input layer is simply just the number of inputs that our data has.  We can get this using ```df.shape```.  \n",
        "\n",
        "Second, we are going to find the second easiest thing to find, the number of nodes in our output layer.  This is simply just the number of unique values in our target column.  For this example, there are only two unique values, either survived or died.  So, we are going to use 2 nodes.\n",
        "\n",
        "Next, we are going to find the number of nodes in our hidden layers.  For this, there isn't really a hardcoded number to set.  When deciding, there are a few rules of thumb.  One, the most nodes per layer, the longer training will take, and the higher the chances of overfitting.  Two, the less the nodes, the more you may underfit, and three, your first hidden layer should have more nodes than your second.  The reason for this, is that it will take longer to train, and you may also have a problem with vanishing or exploding gradients.  \n",
        "\n",
        "So, for this example, we are going to use 300 nodes, and 100 nodes."
      ]
    },
    {
      "metadata": {
        "id": "hCEJnlg9eYUQ",
        "colab_type": "code",
        "outputId": "127706fb-396b-4ba9-e63e-18c1ee196172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#get the input shape\n",
        "train.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "vgmj56UHez2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create vars. to hold input sizes\n",
        "n_inputs = 7\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XscoDDPde-5p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#now lets create placeholders for our X and y inputs.\n",
        "#we specify None for the first dimension, since we want to be able to input any number of samples.\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "\n",
        "y = tf.placeholder(tf.int64, shape=(None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cm82S5SRfiO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have created placeholders to hold our input varibles, we can go on and create the actual node and layer part of our model.  For this we are going to use ```tf.layers.dense()```.  This function creates a series of interconnected nodes.\n",
        "\n",
        "We are first going to create an input layer, then we are going to create the first hidden layers and specify the outputs as from the input layer as the input.  Then, we are going to create the second hidden layer, and specify the outputs from the first hidden layer as the input.  Lastly, we are going to create the output layer, and specify the outputs from the second hidden layer.  As mentioned before, we are going to set the activation function to RELU, since it converges faster than the sigmoid function.\n",
        "\n",
        "You can read up on how exactly an ANN works [here](https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/)."
      ]
    },
    {
      "metadata": {
        "id": "FcOWtJdAqVKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"nn\"):  #create a name scope to hold all of the ANN nodes and layers.\n",
        "  input_layer = tf.layers.dense(X, n_inputs, tf.nn.relu)\n",
        "  hidden_layer1 = tf.layers.dense(input_layer, n_hidden1, tf.nn.relu)\n",
        "  hidden_layer2 = tf.layers.dense(hidden_layer1, n_hidden2, tf.nn.relu)\n",
        "  output_layer = tf.layers.dense(hidden_layer2, n_outputs, tf.nn.relu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVnc8HG2rR73",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not that we have created our ANN layers, we need to specify a loss function.  If you read the link attached above, you would learn that an ANN works by using backpropagation in order to learn what parameters decrease the loss function the most.  This process is known as training the model.  So, in order to actually train the model, we are going to need to create some sort of loss function.\n",
        "\n",
        "In our case, since we are doing a classification problem, we are going to just use accuracy.  However, there is a catch: since our model will actually output class accuracies (like softmax models), instead of just the class, we will want to use cross_entropy as our loss.  We can use ```tf.nn.softmax_cross_entropy_with_logits_v2()``` to find the cross entropy of our model (```tf.nn.softmax_cross_entropy_with_logits()``` is soon to be depreciated as of this post).  Since this function will then find the cross entropy for each prediction our model makes, we will be left with a big list of losses.  Since our model will only want one loss to try to minimize, we will just take the mean of the errors.  For this we will use ```tf.reduce_mean()```."
      ]
    },
    {
      "metadata": {
        "id": "Pd3lsfV1szWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"loss\"):  #create name scope to hold loss operations\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output_layer)\n",
        "  loss = tf.reduce_mean(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZM4yjxb9tEnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And now that we have created a loss function, we will need a training step to actually try to minimize it.  Thankfully, tensorflow comes with a ton of these operation built in.  For this example, we are just going to use a simple gradient descent operation (use ```tf.train.GradientDescentOptimizer()```).  However, if you want to change things up, you can use other training operations (you can read up on them [here](https://www.tensorflow.org/api_docs/python/tf/train)).\n",
        "\n",
        "After we create an object for the training operation, we the use ```object.minimize(loss)``` to tell it to actually start the training process."
      ]
    },
    {
      "metadata": {
        "id": "MEwbv5e3vLpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"train\"):  #create a name scope to hold the training operations\n",
        "  minimizer = tf.train.GradientDescentOptimizer(0.001)  #the parameter here is the learning rate.\n",
        "  train_op = minimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Pg2lTndvcVN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like we are almost done!  Now that we have created a trainable model, we are going to want to create a way to evaluate the performance of the model.  First, we are going to find the correct values that our model predicted using ```tg.nn.in_top_k()```.  Then we are going to find the accuracy by finding the mean of the correct variable."
      ]
    },
    {
      "metadata": {
        "id": "2a3ok3mDwD3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "  correct = tf.nn.in_top_k(output_layer, y, 1)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x77V_NNfxkNn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Phase"
      ]
    },
    {
      "metadata": {
        "id": "WbszRhmXwiZX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At last, we are ready to actually train our model.  For this, we first need to use ```tf.global_variables_initializer()``` to initialize and create all of the variables and placeholders that tensorflow created.  Next, we will need to execute everything in a session using ```tf.Session()```.  A simple ```with``` statement will be ideal.  Lastly, we will train out model by calling a loop a certain number of times, and calling the train_op variable in the loop.  The number of times that we loop through our training operation is called the number of epochs.\n",
        "\n",
        "It is also worth noting that if we had a large number of features and/or samples in our dataset, we would want to use batches instead of the whole data.  However, since we are not using a lot of either, we can just feed to data directly to tensorflow.\n",
        "\n",
        "When we call our training operation, we will also need to feed it values to fill the placeholders.  Remember that we need to feed data to our placeholders, or else we will cause an error as we will basically be performing arithmetic on null variables."
      ]
    },
    {
      "metadata": {
        "id": "Wh-Q5bQx5uA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2104
        },
        "outputId": "a4e78072-b890-463f-ca36-92dcd8c2936a"
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  \n",
        "  data_x = train.drop(['Survived'], axis=1).values\n",
        "  data_y = train['Survived'].values\n",
        "  \n",
        "  for _ in range(1000):\n",
        "    sess.run(train_op, feed_dict={X:data_x, y:data_y})"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[891,2] labels_size=[1,891]\n\t [[{{node loss_3/softmax_cross_entropy_with_logits}} = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](nn_3/dense_3/Relu, loss_3/softmax_cross_entropy_with_logits/Reshape_1)]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-d79f6471a62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[891,2] labels_size=[1,891]\n\t [[node loss_3/softmax_cross_entropy_with_logits (defined at <ipython-input-83-30e992e0ecf4>:2)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](nn_3/dense_3/Relu, loss_3/softmax_cross_entropy_with_logits/Reshape_1)]]\n\nCaused by op 'loss_3/softmax_cross_entropy_with_logits', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-83-30e992e0ecf4>\", line 2, in <module>\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output_layer)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1864, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7210, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[891,2] labels_size=[1,891]\n\t [[node loss_3/softmax_cross_entropy_with_logits (defined at <ipython-input-83-30e992e0ecf4>:2)  = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](nn_3/dense_3/Relu, loss_3/softmax_cross_entropy_with_logits/Reshape_1)]]\n"
          ]
        }
      ]
    }
  ]
}